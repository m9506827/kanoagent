"""
ä½¿ç”¨æœ¬åœ°é–‹æº LLM çš„ Crew é…ç½®
ä¸è€ƒæ…®æˆæœ¬ï¼Œè¿½æ±‚æœ€ä½³é–‹æºæ¨¡å‹é…ç½®
"""
from crewai import Crew, Process
from agents import (
    ProductManagerAgent,
    DesignerAgent,
    ArchitectAgent,
    DeveloperAgent,
    ReviewerAgent,
    TechnicalAgent,
)
from tasks.tasks import create_tasks
import os
from dotenv import load_dotenv

load_dotenv()

def create_plant_diagnosis_crew_local_llm():
    """å‰µå»ºæ¤ç‰©è¨ºæ–·ç³»çµ±é–‹ç™¼åœ˜éšŠ - ä½¿ç”¨æœ¬åœ°é–‹æº LLMï¼ˆæœ€ä½³é…ç½®ï¼‰"""
    
    # ============================================
    # æœ¬åœ°é–‹æº LLM é…ç½®ï¼ˆé€šé Ollamaï¼‰
    # ============================================
    
    # æª¢æŸ¥ Ollama æ˜¯å¦é‹è¡Œ
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        if response.status_code != 200:
            raise ConnectionError("Ollama æœªé‹è¡Œ")
    except:
        raise ValueError(
            "è«‹å…ˆå•Ÿå‹• Ollama æœå‹™ï¼š\n"
            "1. å®‰è£ Ollama: https://ollama.ai/download\n"
            "2. ä¸‹è¼‰æ¨¡å‹ï¼ˆè¦‹ä¸‹æ–¹å»ºè­°ï¼‰\n"
            "3. ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œ"
        )
    
    # ============================================
    # æ ¹æ“š Role é…ç½®æœ€ä½³é–‹æº LLM
    # ============================================
    
    # 1. Product Manager - éœ€è¦åˆ†æã€è¦åŠƒã€æ–‡æª”ç”Ÿæˆ
    # æ¨è–¦ï¼šLlama 3.3 70B æˆ– Qwen2.5 72Bï¼ˆæ–‡æª”ç”Ÿæˆèƒ½åŠ›å¼·ï¼‰
    pm_llm = "ollama/llama3.3:70b"  # æœ€ä½³ï¼šåˆ†æèƒ½åŠ›å¼·ï¼Œé©åˆ PRD
    # å‚™é¸ï¼šollama/qwen2.5:72bï¼ˆä¸­æ–‡èƒ½åŠ›æ›´å¼·ï¼‰
    
    # 2. Designer - éœ€è¦å‰µæ„ã€è¦–è¦ºè¨­è¨ˆæ€ç¶­
    # æ¨è–¦ï¼šLlama 3.3 70B æˆ– Mistral Largeï¼ˆå‰µæ„èƒ½åŠ›å¼·ï¼‰
    designer_llm = "ollama/llama3.3:70b"  # æœ€ä½³ï¼šå‰µæ„è¨­è¨ˆèƒ½åŠ›ä½³
    # å‚™é¸ï¼šollama/mistral-largeï¼ˆå‰µæ„èƒ½åŠ›ä¹Ÿä¸éŒ¯ï¼‰
    
    # 3. Architect - éœ€è¦æŠ€è¡“æ·±åº¦ã€ç³»çµ±è¨­è¨ˆ
    # æ¨è–¦ï¼šDeepSeek Coder æˆ– CodeLlama 70Bï¼ˆæŠ€è¡“èƒ½åŠ›æœ€å¼·ï¼‰
    architect_llm = "ollama/deepseek-coder:33b"  # æœ€ä½³ï¼šæŠ€è¡“æ¶æ§‹è¨­è¨ˆèƒ½åŠ›å¼·
    # å‚™é¸ï¼šollama/codellama:70b
    
    # 4. Developer - éœ€è¦ç¨‹å¼ç¢¼ç”Ÿæˆèƒ½åŠ›
    # æ¨è–¦ï¼šDeepSeek Coder æˆ– CodeLlama 70Bï¼ˆç¨‹å¼ç¢¼èƒ½åŠ›æœ€å¼·ï¼‰
    developer_llm = "ollama/deepseek-coder:33b"  # æœ€ä½³ï¼šç¨‹å¼ç¢¼ç”Ÿæˆèƒ½åŠ›æœ€å¼·
    # å‚™é¸ï¼šollama/codellama:70b
    
    # 5. Reviewer - éœ€è¦åˆ†æã€æ‰¹åˆ¤æ€§æ€ç¶­
    # æ¨è–¦ï¼šLlama 3.3 70B æˆ– Qwen2.5 72Bï¼ˆåˆ†æèƒ½åŠ›å¼·ï¼‰
    reviewer_llm = "ollama/llama3.3:70b"  # æœ€ä½³ï¼šåˆ†æèƒ½åŠ›å¼·ï¼Œé©åˆ Code Review
    # å‚™é¸ï¼šollama/qwen2.5:72b
    
    # 6. Technical - éœ€è¦å¿«é€Ÿå›æ‡‰ã€å•é¡Œè§£æ±º
    # æ¨è–¦ï¼šLlama 3.2 3B æˆ– Phi-3ï¼ˆé€Ÿåº¦å¿«ï¼‰
    technical_llm = "ollama/llama3.2:3b"  # æœ€ä½³ï¼šé€Ÿåº¦å¿«ï¼Œå›æ‡‰å“è³ªè¶³å¤ 
    # å‚™é¸ï¼šollama/phi3:14b
    
    # å‰µå»ºæ‰€æœ‰ Agentsï¼ˆä½¿ç”¨ä¸åŒçš„æœ¬åœ° LLMï¼‰
    product_manager = ProductManagerAgent(pm_llm)
    designer = DesignerAgent(designer_llm)
    architect = ArchitectAgent(architect_llm)
    developer = DeveloperAgent(developer_llm)
    reviewer = ReviewerAgent(reviewer_llm)
    technical = TechnicalAgent(technical_llm)
    
    # é¡¯ç¤ºä½¿ç”¨çš„ LLM é…ç½®
    print("\n" + "="*60)
    print("æœ¬åœ°é–‹æº LLM é…ç½®ï¼ˆæœ€ä½³é…ç½®ï¼‰")
    print("="*60)
    print(f"Product Manager: {pm_llm}")
    print(f"Designer:        {designer_llm}")
    print(f"Architect:       {architect_llm}")
    print(f"Developer:       {developer_llm}")
    print(f"Reviewer:        {reviewer_llm}")
    print(f"Technical:       {technical_llm}")
    print("="*60)
    print("\nğŸ’¡ æç¤ºï¼šç¢ºä¿å·²ä¸‹è¼‰æ‰€æœ‰éœ€è¦çš„æ¨¡å‹")
    print("   ä½¿ç”¨å‘½ä»¤ï¼šollama pull <model_name>\n")
    
    # å‰µå»ºæ‰€æœ‰ä»»å‹™
    tasks = create_tasks(
        product_manager,
        designer,
        architect,
        developer,
        reviewer,
        technical,
    )
    
    # å‰µå»º Crew
    crew = Crew(
        agents=[
            product_manager,
            designer,
            architect,
            developer,
            reviewer,
            technical,
        ],
        tasks=tasks,
        process=Process.sequential,
        verbose=True,
    )
    
    return crew

if __name__ == "__main__":
    crew = create_plant_diagnosis_crew_local_llm()
    result = crew.kickoff()
    print("\n" + "="*50)
    print("å°ˆæ¡ˆå®Œæˆï¼")
    print("="*50)
    print(result)
